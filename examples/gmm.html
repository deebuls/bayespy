<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">


<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>Gaussian mixture model &mdash; BayesPy v0.3.3 Documentation</title>
    
    <link rel="stylesheet" href="../_static/sphinxdoc.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '0.3.3',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="top" title="BayesPy v0.3.3 Documentation" href="../index.html" />
    <link rel="up" title="Examples" href="examples.html" />
    <link rel="next" title="Bernoulli mixture model" href="bmm.html" />
    <link rel="prev" title="Linear regression" href="regression.html" /> 
  </head>
  <body>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             accesskey="I">index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="bmm.html" title="Bernoulli mixture model"
             accesskey="N">next</a> |</li>
        <li class="right" >
          <a href="regression.html" title="Linear regression"
             accesskey="P">previous</a> |</li>
        <li><a href="../index.html">BayesPy v0.3.3 Documentation</a> &raquo;</li>
          <li><a href="examples.html" accesskey="U">Examples</a> &raquo;</li> 
      </ul>
    </div>
      <div class="sphinxsidebar">
        <div class="sphinxsidebarwrapper">
  <h3><a href="../index.html">Table Of Contents</a></h3>
  <ul>
<li><a class="reference internal" href="#">Gaussian mixture model</a><ul>
<li><a class="reference internal" href="#data">Data</a></li>
<li><a class="reference internal" href="#model">Model</a></li>
<li><a class="reference internal" href="#inference">Inference</a></li>
<li><a class="reference internal" href="#results">Results</a></li>
<li><a class="reference internal" href="#advanced-next-steps">Advanced next steps</a><ul>
<li><a class="reference internal" href="#joint-node-for-mean-and-precision">Joint node for mean and precision</a></li>
<li><a class="reference internal" href="#fast-collapsed-inference">Fast collapsed inference</a></li>
</ul>
</li>
</ul>
</li>
</ul>

  <h4>Previous topic</h4>
  <p class="topless"><a href="regression.html"
                        title="previous chapter">Linear regression</a></p>
  <h4>Next topic</h4>
  <p class="topless"><a href="bmm.html"
                        title="next chapter">Bernoulli mixture model</a></p>
  <h3>This Page</h3>
  <ul class="this-page-menu">
    <li><a href="../_sources/examples/gmm.txt"
           rel="nofollow">Show Source</a></li>
  </ul>
<div id="searchbox" style="display: none">
  <h3>Quick search</h3>
    <form class="search" action="../search.html" method="get">
      <input type="text" name="q" />
      <input type="submit" value="Go" />
      <input type="hidden" name="check_keywords" value="yes" />
      <input type="hidden" name="area" value="default" />
    </form>
    <p class="searchtip" style="font-size: 90%">
    Enter search terms or a module, class or function name.
    </p>
</div>
<script type="text/javascript">$('#searchbox').show(0);</script>
        </div>
      </div>

    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body">
            
  <div class="section" id="gaussian-mixture-model">
<h1>Gaussian mixture model<a class="headerlink" href="#gaussian-mixture-model" title="Permalink to this headline">¶</a></h1>
<p>This example demonstrates the use of Gaussian mixture model for flexible density
estimation, clustering or classification.</p>
<div class="section" id="data">
<h2>Data<a class="headerlink" href="#data" title="Permalink to this headline">¶</a></h2>
<p>First, let us generate some artificial data for the analysis.  The data are
two-dimensional vectors from one of the four different Gaussian distributions:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y1</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[[</span><span class="mf">0.1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y2</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="mi">2</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span> <span class="p">[[</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.5</span><span class="p">],</span> <span class="p">[</span><span class="o">-</span><span class="mf">1.5</span><span class="p">,</span> <span class="mi">2</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y3</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">([</span><span class="o">-</span><span class="mi">2</span><span class="p">,</span> <span class="o">-</span><span class="mi">2</span><span class="p">],</span> <span class="p">[[</span><span class="mf">0.5</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">]],</span> <span class="n">size</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">vstack</span><span class="p">([</span><span class="n">y0</span><span class="p">,</span> <span class="n">y1</span><span class="p">,</span> <span class="n">y2</span><span class="p">,</span> <span class="n">y3</span><span class="p">])</span>
</pre></div>
</div>
<p>Thus, there are 200 data vectors in total.  The data looks as follows:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="nn">bayespy.plot</span> <span class="kn">as</span> <span class="nn">bpplt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">bpplt</span><span class="o">.</span><span class="n">pyplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">y</span><span class="p">[:,</span><span class="mi">0</span><span class="p">],</span> <span class="n">y</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="s">&#39;rx&#39;</span><span class="p">)</span>
<span class="go">[&lt;matplotlib.lines.Line2D object at 0x...&gt;]</span>
</pre></div>
</div>
<p>(<a class="reference external" href="../examples/gmm-1.py">Source code</a>, <a class="reference external" href="../examples/gmm-1.png">png</a>, <a class="reference external" href="../examples/gmm-1.hires.png">hires.png</a>, <a class="reference external" href="../examples/gmm-1.pdf">pdf</a>)</p>
<div class="figure">
<img alt="../_images/gmm-1.png" src="../_images/gmm-1.png" />
</div>
</div>
<div class="section" id="model">
<h2>Model<a class="headerlink" href="#model" title="Permalink to this headline">¶</a></h2>
<p>For clarity, let us denote the number of the data vectors with <tt class="docutils literal"><span class="pre">N</span></tt></p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">N</span> <span class="o">=</span> <span class="mi">200</span>
</pre></div>
</div>
<p>and the dimensionality of the data vectors with <tt class="docutils literal"><span class="pre">D</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">D</span> <span class="o">=</span> <span class="mi">2</span>
</pre></div>
</div>
<p>We will use a &#8220;large enough&#8221; number of Gaussian clusters in our model:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">K</span> <span class="o">=</span> <span class="mi">10</span>
</pre></div>
</div>
<p>Cluster assignments <tt class="docutils literal"><span class="pre">Z</span></tt> and the prior for the cluster assignment probabilities
<tt class="docutils literal"><span class="pre">alpha</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayespy.nodes</span> <span class="kn">import</span> <span class="n">Dirichlet</span><span class="p">,</span> <span class="n">Categorical</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">alpha</span> <span class="o">=</span> <span class="n">Dirichlet</span><span class="p">(</span><span class="mf">1e-5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">K</span><span class="p">),</span>
<span class="gp">... </span>                  <span class="n">name</span><span class="o">=</span><span class="s">&#39;alpha&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Z</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span>
<span class="gp">... </span>                <span class="n">plates</span><span class="o">=</span><span class="p">(</span><span class="n">N</span><span class="p">,),</span>
<span class="gp">... </span>                <span class="n">name</span><span class="o">=</span><span class="s">&#39;z&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>The mean vectors and the precision matrices of the clusters:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayespy.nodes</span> <span class="kn">import</span> <span class="n">Gaussian</span><span class="p">,</span> <span class="n">Wishart</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">mu</span> <span class="o">=</span> <span class="n">Gaussian</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">D</span><span class="p">),</span> <span class="mf">1e-5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">D</span><span class="p">),</span>
<span class="gp">... </span>              <span class="n">plates</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,),</span>
<span class="gp">... </span>              <span class="n">name</span><span class="o">=</span><span class="s">&#39;mu&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Lambda</span> <span class="o">=</span> <span class="n">Wishart</span><span class="p">(</span><span class="n">D</span><span class="p">,</span> <span class="mf">1e-5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">D</span><span class="p">),</span>
<span class="gp">... </span>                 <span class="n">plates</span><span class="o">=</span><span class="p">(</span><span class="n">K</span><span class="p">,),</span>
<span class="gp">... </span>                 <span class="n">name</span><span class="o">=</span><span class="s">&#39;Lambda&#39;</span><span class="p">)</span>
</pre></div>
</div>
<p>If either the mean or precision should be shared between clusters, then that
node should not have plates, that is, <tt class="docutils literal"><span class="pre">plates=()</span></tt>.  The data vectors are from
a Gaussian mixture with cluster assignments <tt class="docutils literal"><span class="pre">Z</span></tt> and Gaussian component
parameters <tt class="docutils literal"><span class="pre">mu</span></tt> and <tt class="docutils literal"><span class="pre">Lambda</span></tt>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayespy.nodes</span> <span class="kn">import</span> <span class="n">Mixture</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span> <span class="o">=</span> <span class="n">Mixture</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="n">Gaussian</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span>
<span class="gp">... </span>            <span class="n">name</span><span class="o">=</span><span class="s">&#39;Y&#39;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">Z</span><span class="o">.</span><span class="n">initialize_from_random</span><span class="p">()</span>
</pre></div>
</div>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span> <span class="nn">bayespy.inference</span> <span class="kn">import</span> <span class="n">VB</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">Q</span> <span class="o">=</span> <span class="n">VB</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">Lambda</span><span class="p">,</span> <span class="n">Z</span><span class="p">,</span> <span class="n">alpha</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="inference">
<h2>Inference<a class="headerlink" href="#inference" title="Permalink to this headline">¶</a></h2>
<p>Before running the inference algorithm, we provide the data:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">Y</span><span class="o">.</span><span class="n">observe</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>Then, run VB iteration until convergence:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">Q</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">repeat</span><span class="o">=</span><span class="mi">1000</span><span class="p">)</span>
<span class="go">Iteration 1: loglike=-1.402345e+03 (... seconds)</span>
<span class="gp">...</span>
<span class="go">Iteration 61: loglike=-8.888464e+02 (... seconds)</span>
<span class="go">Converged at iteration 61.</span>
</pre></div>
</div>
<p>The algorithm converges very quickly.  Note that the default update order of the
nodes was such that <tt class="docutils literal"><span class="pre">mu</span></tt> and <tt class="docutils literal"><span class="pre">Lambda</span></tt> were updated before <tt class="docutils literal"><span class="pre">Z</span></tt>, which is
what we wanted because <tt class="docutils literal"><span class="pre">Z</span></tt> was initialized randomly.</p>
</div>
<div class="section" id="results">
<h2>Results<a class="headerlink" href="#results" title="Permalink to this headline">¶</a></h2>
<p>For two-dimensional Gaussian mixtures, the mixture components can be plotted
using <a class="reference internal" href="../user_api/generated/generated/bayespy.plot.gaussian_mixture_2d.html#bayespy.plot.gaussian_mixture_2d" title="bayespy.plot.gaussian_mixture_2d"><tt class="xref py py-func docutils literal"><span class="pre">gaussian_mixture_2d()</span></tt></a>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="gp">&gt;&gt;&gt; </span><span class="n">bpplt</span><span class="o">.</span><span class="n">gaussian_mixture_2d</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
<p>(<a class="reference external" href="../examples/gmm-2.py">Source code</a>, <a class="reference external" href="../examples/gmm-2.png">png</a>, <a class="reference external" href="../examples/gmm-2.hires.png">hires.png</a>, <a class="reference external" href="../examples/gmm-2.pdf">pdf</a>)</p>
<div class="figure">
<img alt="../_images/gmm-2.png" src="../_images/gmm-2.png" />
</div>
<p>The function is called with <tt class="docutils literal"><span class="pre">scale=2</span></tt> which means that each ellipse shows two
standard deviations.  From the ten cluster components, the model uses
effectively the correct number of clusters (4).  These clusters capture the true
density accurately.</p>
<p>In addition to clustering and density estimation, this model could also be used
for classification by setting the known class assignments as observed.</p>
</div>
<div class="section" id="advanced-next-steps">
<h2>Advanced next steps<a class="headerlink" href="#advanced-next-steps" title="Permalink to this headline">¶</a></h2>
<div class="section" id="joint-node-for-mean-and-precision">
<h3>Joint node for mean and precision<a class="headerlink" href="#joint-node-for-mean-and-precision" title="Permalink to this headline">¶</a></h3>
<p>The next step for improving the results could be to use <a class="reference internal" href="../user_api/generated/generated/bayespy.nodes.GaussianWishart.html#bayespy.nodes.GaussianWishart" title="bayespy.nodes.GaussianWishart"><tt class="xref py py-class docutils literal"><span class="pre">GaussianWishart</span></tt></a>
node for modelling the mean vectors <tt class="docutils literal"><span class="pre">mu</span></tt> and precision matrices <tt class="docutils literal"><span class="pre">Lambda</span></tt>
jointly without factorization.  This should improve the accuracy of the
posterior approximation and the speed of the VB estimation.  However, the
implementation is a bit more complex.</p>
</div>
<div class="section" id="fast-collapsed-inference">
<h3>Fast collapsed inference<a class="headerlink" href="#fast-collapsed-inference" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="related">
      <h3>Navigation</h3>
      <ul>
        <li class="right" style="margin-right: 10px">
          <a href="../genindex.html" title="General Index"
             >index</a></li>
        <li class="right" >
          <a href="../py-modindex.html" title="Python Module Index"
             >modules</a> |</li>
        <li class="right" >
          <a href="bmm.html" title="Bernoulli mixture model"
             >next</a> |</li>
        <li class="right" >
          <a href="regression.html" title="Linear regression"
             >previous</a> |</li>
        <li><a href="../index.html">BayesPy v0.3.3 Documentation</a> &raquo;</li>
          <li><a href="examples.html" >Examples</a> &raquo;</li> 
      </ul>
    </div>
    <div class="footer">
        &copy; Copyright 2011-2015, Jaakko Luttinen, MIT.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.2.3.
    </div>
  </body>
</html>